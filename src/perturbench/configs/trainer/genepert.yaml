_target_: lightning.pytorch.trainer.Trainer

default_root_dir: ${paths.output_dir}

min_epochs: 10 # prevents early stopping
max_epochs: 100

accelerator: gpu
# devices: 1
# Use 2 GPUs for training
devices: [0,1,2,3]
strategy: ddp_find_unused_parameters_true # use distributed data parallel for multi-gpu training

# mixed precision for extra speed-up
precision: 32

# perform a validation loop every N training epochs
check_val_every_n_epoch: 1

# set True to to ensure deterministic results
# makes training slower but gives more reproducibility than just setting seeds
deterministic: False

# log every N steps
log_every_n_steps: 10