# GenePert Model Configuration

_target_: perturbench.modelcore.models.GenePert

# Whether to use pretrained cell embeddings (needed for some transforms)
use_cell_emb: false
use_mask: true  # Unified mask switch for training loss and evaluation

# Path to gene embeddings (GenePT embeddings)
gene_embedding_path: /fs-computility-new/upzd_share/maoxinjie/AIVC/integrate_perturbench/notebooks/neurips2025/perturbench_data/GenePT_gene_embedding_ada_text.pickle


batch_size: 1000

# Network architecture
hidden_size: 128
# Optimization
lr: 1e-3
wd: 1e-5

# Learning rate scheduler
lr_scheduler_freq: 1
lr_scheduler_interval: "epoch"
lr_scheduler_patience: 15
lr_scheduler_factor: 0.2
lr_scheduler_mode: onecycle  # OneCycleLR for better convergence
lr_scheduler_max_lr: 0.001   # Max learning rate for OneCycleLR
# lr_scheduler_total_steps: auto-calculated from dataloader size * max_epochs
